{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4017efb5",
   "metadata": {},
   "source": [
    "John Samana\n",
    "Sure Trust(G34 - Python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b881db8",
   "metadata": {},
   "source": [
    "Question 1 (NumPy) – Titanic Dataset Survival Analysis\n",
    "1. Load the Titanic dataset using Pandas and convert the following numeric columns into a\n",
    "NumPy array:\n",
    "o age, fare, and survived.\n",
    "2. Using NumPy (not Pandas), perform the following:\n",
    "o a) Remove rows with missing values in any of the selected columns.\n",
    "o b) Normalize age and fare columns using Z-score normalization.\n",
    "o c) Compute the mean age and mean fare for:\n",
    "▪ passengers who survived\n",
    "▪ passengers who did not survive\n",
    "o d) Use np.where() to classify fare as:\n",
    "▪ \"Low\" if fare < mean,\n",
    "▪ \"High\" otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426382a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba3624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31f2a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_data = pd.read_csv('//Users//johnsamana//Downloads//Python//Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75601996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Gender   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4f6ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.      7.25    0.    ]\n",
      " [38.     71.2833  1.    ]\n",
      " [26.      7.925   1.    ]\n",
      " ...\n",
      " [    nan 23.45    0.    ]\n",
      " [26.     30.      1.    ]\n",
      " [32.      7.75    0.    ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the numeric columns and convert to NumPy array\n",
    "columns = ['Age', 'Fare', 'Survived']\n",
    "titanic_array = titanic_data[columns].to_numpy()\n",
    "\n",
    "# Output\n",
    "print(titanic_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84bb02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.      7.25    0.    ]\n",
      " [38.     71.2833  1.    ]\n",
      " [26.      7.925   1.    ]\n",
      " ...\n",
      " [19.     30.      1.    ]\n",
      " [26.     30.      1.    ]\n",
      " [32.      7.75    0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "cleaned_data = titanic_array[~np.isnan(titanic_array).any(axis=1)]\n",
    "\n",
    "# Output\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92483524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.53037664 -0.51897787]\n",
      " [ 0.57183099  0.69189675]\n",
      " [-0.25482473 -0.50621356]\n",
      " ...\n",
      " [-0.73704057 -0.08877362]\n",
      " [-0.25482473 -0.08877362]\n",
      " [ 0.15850313 -0.50952283]]\n"
     ]
    }
   ],
   "source": [
    "# Z-score normalization\n",
    "mean_age, std_age = cleaned_data[:, 0].mean(), cleaned_data[:, 0].std()\n",
    "mean_fare, std_fare = cleaned_data[:, 1].mean(), cleaned_data[:, 1].std()\n",
    "\n",
    "cleaned_data[:, 0] = (cleaned_data[:, 0] - mean_age) / std_age\n",
    "cleaned_data[:, 1] = (cleaned_data[:, 1] - mean_fare) / std_fare\n",
    "\n",
    "# Output\n",
    "print(cleaned_data[:, :2])  # Normalized age and fare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d281cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived - Mean Age: -0.09337269255785864 Mean Fare: 0.3242830655233994\n",
      "Not Survived - Mean Age: 0.06386339821174336 Mean Fare: -0.22179737972119304\n"
     ]
    }
   ],
   "source": [
    "# Split data by survival\n",
    "survived = cleaned_data[cleaned_data[:, 2] == 1]\n",
    "not_survived = cleaned_data[cleaned_data[:, 2] == 0]\n",
    "\n",
    "# Compute means\n",
    "mean_age_survived = survived[:, 0].mean()\n",
    "mean_fare_survived = survived[:, 1].mean()\n",
    "\n",
    "mean_age_not_survived = not_survived[:, 0].mean()\n",
    "mean_fare_not_survived = not_survived[:, 1].mean()\n",
    "\n",
    "# Output\n",
    "print(\"Survived - Mean Age:\", mean_age_survived, \"Mean Fare:\", mean_fare_survived)\n",
    "print(\"Not Survived - Mean Age:\", mean_age_not_survived, \"Mean Fare:\", mean_fare_not_survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b621731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low' 'High' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High'\n",
      " 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'Low' 'High'\n",
      " 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'High'\n",
      " 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'High'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'High' 'High'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'High'\n",
      " 'High' 'Low' 'High' 'High' 'Low' 'High' 'High' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'High' 'High' 'Low' 'High' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'High' 'Low'\n",
      " 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High'\n",
      " 'High' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'High' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'High' 'High' 'Low' 'Low' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'High' 'Low' 'High' 'High' 'Low' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'High'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'High' 'Low' 'Low' 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'High' 'High' 'Low' 'High' 'High' 'High' 'High' 'Low' 'Low' 'High'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'High' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'High' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'High'\n",
      " 'High' 'High' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'High' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low'\n",
      " 'High' 'Low' 'Low' 'Low' 'Low' 'Low' 'Low' 'High' 'Low' 'Low' 'Low' 'Low'\n",
      " 'Low' 'Low' 'Low' 'Low' 'Low' 'Low']\n"
     ]
    }
   ],
   "source": [
    "# Classify fare\n",
    "mean_fare = cleaned_data[:, 1].mean()\n",
    "fare_classification = np.where(cleaned_data[:, 1] < mean_fare, \"Low\", \"High\")\n",
    "\n",
    "# Output\n",
    "print(fare_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259473bb",
   "metadata": {},
   "source": [
    "Question 2 (Pandas) – Iris Dataset Summary Report\n",
    "1. Load the Iris dataset using Pandas.\n",
    "2. Create a new column called petal_ratio = petal_length / petal_width.\n",
    "3. Answer the following:\n",
    "o a) What is the average petal_ratio per species?\n",
    "o b) Which species has the highest standard deviation in sepal_length?\n",
    "o c) Filter the dataset to only include rows where sepal_width is above the overall\n",
    "mean.\n",
    "o d) Split the DataFrame into two subsets:\n",
    "▪ One with petal_ratio < 2\n",
    "▪ One with petal_ratio ≥ 2\n",
    "▪ Then stack them vertically using pd.concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris_data = pd.read_excel('//Users/johnsamana//Downloads//Python//iris.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "920fa316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety  petal_ratio\n",
      "0           5.1          3.5           1.4          0.2  Setosa          7.0\n",
      "1           4.9          3.0           1.4          0.2  Setosa          7.0\n",
      "2           4.7          3.2           1.3          0.2  Setosa          6.5\n",
      "3           4.6          3.1           1.5          0.2  Setosa          7.5\n",
      "4           5.0          3.6           1.4          0.2  Setosa          7.0\n"
     ]
    }
   ],
   "source": [
    "# Create petal_ratio column\n",
    "iris_data['petal_ratio'] = iris_data['petal.length'] / iris_data['petal.width']\n",
    "\n",
    "# Output\n",
    "print(iris_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f82cde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variety\n",
      "Setosa        6.908000\n",
      "Versicolor    3.242837\n",
      "Virginica     2.780662\n",
      "Name: petal_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Average petal_ratio per species\n",
    "average_petal_ratio = iris_data.groupby('variety')['petal_ratio'].mean()\n",
    "\n",
    "# Output\n",
    "print(average_petal_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67f96828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species with highest std in sepal_length: Virginica\n"
     ]
    }
   ],
   "source": [
    "# Standard deviation of sepal_length per species\n",
    "std_sepal_length = iris_data.groupby('variety')['sepal.length'].std()\n",
    "highest_std_species = std_sepal_length.idxmax()\n",
    "\n",
    "# Output\n",
    "print(\"Species with highest std in sepal_length:\", highest_std_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53196404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety  \\\n",
      "0             5.1          3.5           1.4          0.2     Setosa   \n",
      "2             4.7          3.2           1.3          0.2     Setosa   \n",
      "3             4.6          3.1           1.5          0.2     Setosa   \n",
      "4             5.0          3.6           1.4          0.2     Setosa   \n",
      "5             5.4          3.9           1.7          0.4     Setosa   \n",
      "..            ...          ...           ...          ...        ...   \n",
      "140           6.7          3.1           5.6          2.4  Virginica   \n",
      "141           6.9          3.1           5.1          2.3  Virginica   \n",
      "143           6.8          3.2           5.9          2.3  Virginica   \n",
      "144           6.7          3.3           5.7          2.5  Virginica   \n",
      "148           6.2          3.4           5.4          2.3  Virginica   \n",
      "\n",
      "     petal_ratio  \n",
      "0       7.000000  \n",
      "2       6.500000  \n",
      "3       7.500000  \n",
      "4       7.000000  \n",
      "5       4.250000  \n",
      "..           ...  \n",
      "140     2.333333  \n",
      "141     2.217391  \n",
      "143     2.565217  \n",
      "144     2.280000  \n",
      "148     2.347826  \n",
      "\n",
      "[67 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows\n",
    "mean_sepal_width = iris_data['sepal.width'].mean()\n",
    "filtered_data = iris_data[iris_data['sepal.width'] > mean_sepal_width]\n",
    "\n",
    "# Output\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a8ecc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety  \\\n",
      "0             5.1          3.5           1.4          0.2     Setosa   \n",
      "1             4.9          3.0           1.4          0.2     Setosa   \n",
      "2             4.7          3.2           1.3          0.2     Setosa   \n",
      "3             4.6          3.1           1.5          0.2     Setosa   \n",
      "4             5.0          3.6           1.4          0.2     Setosa   \n",
      "..            ...          ...           ...          ...        ...   \n",
      "145           6.7          3.0           5.2          2.3  Virginica   \n",
      "146           6.3          2.5           5.0          1.9  Virginica   \n",
      "147           6.5          3.0           5.2          2.0  Virginica   \n",
      "148           6.2          3.4           5.4          2.3  Virginica   \n",
      "149           5.9          3.0           5.1          1.8  Virginica   \n",
      "\n",
      "     petal_ratio  \n",
      "0       7.000000  \n",
      "1       7.000000  \n",
      "2       6.500000  \n",
      "3       7.500000  \n",
      "4       7.000000  \n",
      "..           ...  \n",
      "145     2.260870  \n",
      "146     2.631579  \n",
      "147     2.600000  \n",
      "148     2.347826  \n",
      "149     2.833333  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "subset_low = iris_data[iris_data['petal_ratio'] < 2]\n",
    "subset_high = iris_data[iris_data['petal_ratio'] >= 2]\n",
    "\n",
    "# Stack vertically\n",
    "stacked_data = pd.concat([subset_low, subset_high])\n",
    "\n",
    "# Output\n",
    "print(stacked_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
